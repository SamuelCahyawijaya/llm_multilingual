{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afd67bd-f4a5-4c31-8f9a-1ccf391c8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import jsonlines\n",
    "# get_gpt_generation() function from utils\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d79d9b94-3ee9-403f-8026-3f36e08e0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.reasoning_qa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d9a5a3-10a0-415f-a475-241caf305484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6371b28-3a8c-400e-9c40-fe88548891b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reasoning_test(test_examples, test_golds, dataset_name, do_print=False, do_correct=True):\n",
    "    objs = []\n",
    "    for test, gold in zip(test_examples, test_golds):\n",
    "        ###### HERE YOU CAN CHANGE IT TO YOUR OWN MODELS########\n",
    "        gen = get_gpt_generation(test)\n",
    "        ########################################################\n",
    "\n",
    "        # for ease of checking -- but need to verify.\n",
    "        if do_correct:\n",
    "            if 'babi' in dataset_name:\n",
    "                gold = o['gold'].strip().split(\"\\t\")[0]\n",
    "            correct= 1 if gold in gen.lower() else 0\n",
    "        else:\n",
    "            corret = -1\n",
    "            \n",
    "        obj= {\n",
    "            'q': test,\n",
    "            'gold': gold,\n",
    "            'gen': gen,\n",
    "            'correct-rough': correct\n",
    "        }\n",
    "        objs.append(obj)\n",
    "        \n",
    "        with jsonlines.open(f'results/reasoning-{dataset_name}.jsonl', mode='a') as writer:\n",
    "            writer.write(obj) \n",
    "        \n",
    "    if do_print:     \n",
    "        for o in objs:\n",
    "            print(o['q'], \"|\", o['gold'], \"|\", o['gen'].replace(\"\\n\", \" \"), \"|\", o['correct-rough'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe117f22-37b6-489e-8b49-7318d4b0e552",
   "metadata": {},
   "source": [
    "# << Deductive >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf899ba4-bb8d-48bb-97fa-2213e20bbdcd",
   "metadata": {},
   "source": [
    "### Entailmentbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac7df955-f274-44f5-924b-956e1c173693",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = entailmentbank()\n",
    "reasoning_test(test_examples, test_golds, dataset_name='entailmentbank', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f339c7c-b0ab-4722-95d3-fb3c839b1546",
   "metadata": {},
   "source": [
    "### BABI 15 - as is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3ea84-96c5-4c4c-a2d3-6fe12e1ed98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = babi(exp_type = 15, prompt_engineering=False, batching=False)\n",
    "reasoning_test(test_examples, test_golds, dataset_name='babi-15', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd56d4-0185-4ab4-a431-0f8d8d0b4bfe",
   "metadata": {},
   "source": [
    "### BABI 15 - prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e5f69-4637-4208-b93e-ffad2ff356cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = babi(exp_type = 15, prompt_engineering=True, batching=False)\n",
    "reasoning_test(test_examples, test_golds, dataset_name='babi-15-engineering', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2bcb23-2d18-4738-899b-91aac55bd12c",
   "metadata": {},
   "source": [
    "# << Inductive >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931a0ef-f994-45d6-92b2-8bea5a1b49bf",
   "metadata": {},
   "source": [
    "## CLUTRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8915690-97d2-4be6-8302-377afb75e9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = clutrr()\n",
    "reasoning_test(test_examples, test_golds, dataset_name='clutrr', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1694728f-279c-4941-8fe5-d40665ec07b9",
   "metadata": {},
   "source": [
    "## BABI 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be5b1b77-6ac2-43a1-a8ec-79e03223d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds =  babi(exp_type = 16, prompt_engineering=False, batching=False)\n",
    "reasoning_test(test_examples, test_golds, dataset_name='babi-16', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff886fff-b409-47d3-8ad0-613834194166",
   "metadata": {},
   "source": [
    "### BABI 16 - prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba6316e-d4ea-4edc-8d33-77c141358642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = babi(exp_type = 16, prompt_engineering=True, batching=False)\n",
    "reasoning_test(test_examples, test_golds, dataset_name='babi-16-engineering', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b277ca60-ba46-4ef4-bb72-23bd860c3d1f",
   "metadata": {},
   "source": [
    "# << Math >> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898b488-bab6-41b6-8a37-f62a2c2ee695",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = math()\n",
    "reasoning_test(test_examples, test_golds, dataset_name='math', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92794c5f-4483-417c-9d0d-6ce14fa92242",
   "metadata": {},
   "source": [
    "# << Temporal >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a5d778-810c-4028-ba83-9ce526371971",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = timedial()\n",
    "reasoning_test(test_examples, test_golds, dataset_name='timedial', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735cb69-baf3-461a-a02b-b495edc07852",
   "metadata": {},
   "source": [
    "# << Spatial >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee64aa1-ddda-49bc-9269-5b9bda403a80",
   "metadata": {},
   "source": [
    "### Stepgame-hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce634b8-001b-4682-bd39-554169879531",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = step_game('hard')\n",
    "reasoning_test(test_examples, test_golds, dataset_name='stepgame-hard', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8401decb-20b1-4ffe-8a24-14cdb075559c",
   "metadata": {},
   "source": [
    "### Stepgame-basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0eafa-2af8-4be1-849d-98583e9474d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = step_game('basic')\n",
    "reasoning_test(test_examples, test_golds, dataset_name='stepgame-basic', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e07a7c-7628-49af-abfd-030e39dbfb82",
   "metadata": {},
   "source": [
    "# << Commonsense >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6002226-13ff-4d0f-9160-f66740289d11",
   "metadata": {},
   "source": [
    "### commonsense qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd599762-9c6b-4330-bd6c-a960bb11b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, ids, golds = commonsenseqa(num_dataset=30, output_gold=True, save_csv=True)\n",
    "reasoning_test(test_examples, test_golds, dataset_name='commonsenseqa', do_print=False, do_correct=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef1833-4983-4f53-a50c-0a0e0488fc02",
   "metadata": {},
   "source": [
    "### piqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3715f005-cb59-4c25-b08d-53235457ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, ids, golds = piqa(num_dataset=30, output_gold=True, save_csv=True)\n",
    "reasoning_test(test_examples, test_golds, dataset_name='piqa', do_print=False, do_correct=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14257cc6-a301-4ebb-8377-978f124461f2",
   "metadata": {},
   "source": [
    "### pep-3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b48bb1-1e5b-4fbd-9264-404e1eb35781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/pep-3k.csv')\n",
    "test_examples = df['Question'].to_list()\n",
    "golds = df['Label'].to_list()\n",
    "\n",
    "gens = []\n",
    "for ex, answer in zip(test_examples, golds):\n",
    "    prompt = 'Please judge if this predicate is (likely) plausible or implausible: ' + ex\n",
    "    gen = get_gpt_generation(prompt)\n",
    "    gens.append(gen)\n",
    "    print(answer, \" || \", gen)\n",
    "    obj={\n",
    "        'gen': gen,\n",
    "        'tgt': answer,\n",
    "        'prompt': prompt}\n",
    "    with jsonlines.open('results/reasoning_pep3k.jsonl', mode='a') as writer:\n",
    "        writer.write(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ecd69-6597-45f1-a25d-e6d10735caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for g, a in zip(gens, golds):\n",
    "    i+=1\n",
    "    if \"implausible\" in g.lower() or \"Impausible\" in g:\n",
    "        b = 0\n",
    "    else:\n",
    "        b = 1\n",
    "    print(i, \")\", a, f\" | {b} | \", g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0457e76d-8fba-45b6-a90f-aed56b34ba99",
   "metadata": {},
   "source": [
    "# << Causal >>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c00d3c-e0fc-433e-bda3-d1de392b876c",
   "metadata": {},
   "source": [
    "### E-Care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9448d72-0f63-475e-b22c-2dfd56d11e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = ecare()\n",
    "reasoning_test(test_examples, test_golds, dataset_name='ecare', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c96438-0f20-4aca-bda6-fb29a1189467",
   "metadata": {},
   "source": [
    "# << Multi-hop >>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bbdd71-c297-4577-b6d9-e611ffcd9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids, test_golds = hotpot_qa()\n",
    "reasoning_test(test_examples, test_golds, dataset_name='hotpotqa', do_print=False, do_correct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31cd0d-e642-4046-b699-e28f623492aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
