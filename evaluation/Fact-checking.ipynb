{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a664c269-9fa0-4a30-8b81-e5bc309a2c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hallucination import *\n",
    "\n",
    "# get_gpt_generation() function from utils\n",
    "from utils import * \n",
    "\n",
    "import jsonlines\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f4d69ce-c49f-4d98-b01b-87933252072f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fact_checking(test_examples, dataset_name, do_print=False):\n",
    "    results = []\n",
    "    for ex in test_examples:\n",
    "        prompt = ex['input']\n",
    "        score = 'true' if ex['target_scores']['true'] == 1 else 'false'\n",
    "    ###### HERE YOU CAN CHANGE IT TO YOUR OWN MODELS########\n",
    "        gen = get_gpt_generation(prompt)\n",
    "    ########################################################\n",
    "    \n",
    "        gen_split = gen.lower().split()\n",
    "        a = -1\n",
    "        for x in gen_split:\n",
    "            if 'true' in x:\n",
    "                a = 'true'\n",
    "            elif 'false' in x:\n",
    "                a = 'false'\n",
    "        if a == -1:\n",
    "            a = 'x'\n",
    "    \n",
    "        obj = {\n",
    "            'tgt': score, \n",
    "            'gen_a' : a, \n",
    "            'gen' : gen}\n",
    "    \n",
    "        correct = 1 if score == a else 0\n",
    "        results.append(correct)\n",
    "    \n",
    "        with jsonlines.open(f'results/{dataset_name}.jsonl', mode='a') as writer:\n",
    "            writer.write(obj)\n",
    "    \n",
    "        if do_print:\n",
    "            print(obj)\n",
    "\n",
    "        break\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab58f4-e78d-449c-8e2d-6a33154b2da7",
   "metadata": {},
   "source": [
    "# Read Data Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0004dac4-b622-4e1a-bd59-a231691b8691",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sci_test_examples, test_ids = covid_factchecking(exp_type='scientific')\n",
    "social_test_examples, test_ids = covid_factchecking(exp_type='social')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f74d999-0b3a-4e98-88b4-4f34ff17f0b4",
   "metadata": {},
   "source": [
    "## Running exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cccdd46b-82e9-45c5-ba4a-712b48632a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#social covid\n",
    "covid_social_results = fact_checking(social_test_examples, 'covid_social', do_print=False)\n",
    "print(\"Acc.: \", sum(covid_social_results)/ len(covid_social_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca581c1-f4d4-449f-8ca6-ef8eec0b596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scientific covid\n",
    "covid_social_results = fact_checking(sci_test_examples, 'covid_scientific', do_print=False)\n",
    "print(\"Acc.: \", sum(covid_social_results)/ len(covid_social_results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dca16d-5e4b-45ff-89e7-db95b6bb0cfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
