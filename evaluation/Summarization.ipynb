{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5391744-425a-4075-bf91-d9551bc037ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import jsonlines\n",
    "# get_gpt_generation() function from utils\n",
    "from utils import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11adffb7-7315-495d-818e-fbeacc5bc43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarization\n",
    "from src.summarization import *\n",
    "import evaluate\n",
    "import time\n",
    "\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "615c546b-0271-45ba-a1cd-df85aa7be9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarization(test_examples, dataset_name):    \n",
    "    gens, tgts, results, rouge_1 = [], [], [], []\n",
    "    \n",
    "    for idx, example in enumerate(test_examples):\n",
    "        \n",
    "        prompt = example['prompt'][:-1]\n",
    "        tgt = example['tgt']\n",
    "\n",
    "    ###### HERE YOU CAN CHANGE IT TO YOUR OWN MODELS########\n",
    "        gen = get_gpt_generation(prompt)\n",
    "    ########################################################\n",
    "        gens.append(gen)\n",
    "        tgts.append(tgt)\n",
    "    \n",
    "        obj={\n",
    "            'gen': gen,\n",
    "            'tgt': tgt}\n",
    "    \n",
    "        with jsonlines.open(f'results/summarization_result_{dataset_name}.jsonl', mode='a') as writer:\n",
    "            writer.write(obj)\n",
    "\n",
    "        if idx % 10 == 0:\n",
    "            print(idx)\n",
    "            time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5164e101-464f-4674-9d94-d361666d0854",
   "metadata": {},
   "source": [
    "## CNNDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18634e15-9837-4e9b-8084-075ecae48e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "test_examples, test_ids = CNNDM()\n",
    "summarization(test_examples, 'cnndm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b13961-a52b-45c1-bfe4-14bef018ec65",
   "metadata": {},
   "source": [
    "## SAMSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054cd9e0-9d89-472e-a066-58877ebb0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples, test_ids = SAMSum()\n",
    "summarization(test_examples, 'samsum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb50eada-d537-4a0d-a3a8-922a144aa99a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4a1f412-b9b0-4b48-8b64-2e386bb1a785",
   "metadata": {},
   "source": [
    "## Calculate Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79e95286-9f4b-4177-80b6-3e1d27f227b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rouge_score(output_file_dir):\n",
    "    \n",
    "    chatgpt_summary = []\n",
    "    reference = []\n",
    "    \n",
    "    \n",
    "    with jsonlines.open(output_file_dir) as read_file:\n",
    "        for line in read_file.iter():\n",
    "        \tchatgpt_summary.append(line['gen'])\n",
    "        \treference.append(line['tgt'])\n",
    "            \n",
    "    results = rouge.compute(predictions=chatgpt_summary,references=reference)\n",
    "    \n",
    "    return results['rouge1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e238e97-13d5-43a0-b26e-414e47226111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/summarization_result_cnndm.jsonl  : 0.323\n",
      "results/summarization_result_samsum.jsonl  : 0.3326\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_FILES = ['results/summarization_result_cnndm.jsonl', 'results/summarization_result_samsum.jsonl']\n",
    "\n",
    "for file in OUTPUT_FILES:\n",
    "    rouge_score =  get_rouge_score(file)\n",
    "    print(file, \" :\", round(rouge_score, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
